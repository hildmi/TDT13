{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     ID  \\\n",
      "0  691324c4-5c30-44e0-b9e4-45b4f0715e21   \n",
      "1  d4295391-9ca5-4398-b7c8-687e4a984ef1   \n",
      "2  58937fa5-3c2c-426b-8255-5a140fbab675   \n",
      "3  7daf364c-3b33-4cbe-be37-a214edf9a73e   \n",
      "4  22518271-4bb4-4caf-b683-7305da519288   \n",
      "\n",
      "                                                post class_name  class_id  \n",
      "0  i was making questions for my students and i r...       none         5  \n",
      "1  i've recently requested testing accommodations...       adhd         0  \n",
      "2  **cambodia** * koh rong: amazing beaches and a...       none         5  \n",
      "3  synesthesia. what is synesthesia? according to...       none         5  \n",
      "4  iâ€™m phil baran and i teach organic chemistry a...       none         5  \n",
      "class_id\n",
      "0    2465\n",
      "3    2450\n",
      "1    2422\n",
      "2    2407\n",
      "4    2001\n",
      "5    1982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "train_df = pd.read_csv('posts_train.csv')\n",
    "\n",
    "# Explore the first few records\n",
    "print(train_df.head())\n",
    "\n",
    "# Explore the distribution of classes\n",
    "print(train_df['class_id'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('posts_train.csv')\n",
    "val_df = pd.read_csv('posts_val.csv')\n",
    "test_df = pd.read_csv('posts_test.csv')\n",
    "\n",
    "train_df = train_df.sample(frac=0.1, random_state=1)  # Takes a 10% random sample\n",
    "val_df = val_df.sample(frac=0.1, random_state=1)      # same here\n",
    "test_df = test_df.sample(frac=0.1, random_state=1)    # and here\n",
    "\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "# Tokenize your data\n",
    "train_encodings = tokenizer(train_df['post'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_df['post'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_df['post'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "#Labels\n",
    "train_labels = train_df['class_id'].values\n",
    "val_labels = val_df['class_id'].values\n",
    "test_labels = test_df['class_id'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RedditDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the dataset objects\n",
    "train_dataset = RedditDataset(train_encodings, train_labels)\n",
    "val_dataset = RedditDataset(val_encodings, val_labels)\n",
    "test_dataset = RedditDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 4.84 GB, other allocations: 1.88 GB, max allowed: 6.77 GB). Tried to allocate 96.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 28\u001b[0m\n\u001b[1;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     21\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     22\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     23\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     24\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1588'>1589</a>\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1589'>1590</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1590'>1591</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1591'>1592</a>\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1592'>1593</a>\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1593'>1594</a>\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1594'>1595</a>\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1595'>1596</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1888'>1889</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1890'>1891</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1891'>1892</a>\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1893'>1894</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1894'>1895</a>\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1895'>1896</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1896'>1897</a>\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1897'>1898</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1898'>1899</a>\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=1899'>1900</a>\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py:2776\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2772'>2773</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2774'>2775</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2775'>2776</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2777'>2778</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2778'>2779</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py:2801\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2798'>2799</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2799'>2800</a>\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2800'>2801</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2801'>2802</a>\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2802'>2803</a>\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/trainer.py?line=2803'>2804</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py:1545\u001b[0m, in \u001b[0;36mXLNetForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, labels, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1536'>1537</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1537'>1538</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1538'>1539</a>\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1539'>1540</a>\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1540'>1541</a>\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1541'>1542</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1542'>1543</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1544'>1545</a>\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1545'>1546</a>\u001b[0m     input_ids,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1546'>1547</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1547'>1548</a>\u001b[0m     mems\u001b[39m=\u001b[39;49mmems,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1548'>1549</a>\u001b[0m     perm_mask\u001b[39m=\u001b[39;49mperm_mask,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1549'>1550</a>\u001b[0m     target_mapping\u001b[39m=\u001b[39;49mtarget_mapping,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1550'>1551</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1551'>1552</a>\u001b[0m     input_mask\u001b[39m=\u001b[39;49minput_mask,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1552'>1553</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1553'>1554</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1554'>1555</a>\u001b[0m     use_mems\u001b[39m=\u001b[39;49muse_mems,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1555'>1556</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1556'>1557</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1557'>1558</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1558'>1559</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1559'>1560</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1560'>1561</a>\u001b[0m output \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1562'>1563</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msequence_summary(output)\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py:1237\u001b[0m, in \u001b[0;36mXLNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1233'>1234</a>\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1234'>1235</a>\u001b[0m     hidden_states\u001b[39m.\u001b[39mappend((output_h, output_g) \u001b[39mif\u001b[39;00m output_g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m output_h)\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1236'>1237</a>\u001b[0m outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1237'>1238</a>\u001b[0m     output_h,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1238'>1239</a>\u001b[0m     output_g,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1239'>1240</a>\u001b[0m     attn_mask_h\u001b[39m=\u001b[39;49mnon_tgt_mask,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1240'>1241</a>\u001b[0m     attn_mask_g\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1241'>1242</a>\u001b[0m     r\u001b[39m=\u001b[39;49mpos_emb,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1242'>1243</a>\u001b[0m     seg_mat\u001b[39m=\u001b[39;49mseg_mat,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1243'>1244</a>\u001b[0m     mems\u001b[39m=\u001b[39;49mmems[i],\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1244'>1245</a>\u001b[0m     target_mapping\u001b[39m=\u001b[39;49mtarget_mapping,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1245'>1246</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1246'>1247</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1247'>1248</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1248'>1249</a>\u001b[0m output_h, output_g \u001b[39m=\u001b[39m outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=1249'>1250</a>\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py:508\u001b[0m, in \u001b[0;36mXLNetLayer.forward\u001b[0;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=494'>495</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=495'>496</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=496'>497</a>\u001b[0m     output_h,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=505'>506</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=506'>507</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=507'>508</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_attn(\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=508'>509</a>\u001b[0m         output_h,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=509'>510</a>\u001b[0m         output_g,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=510'>511</a>\u001b[0m         attn_mask_h,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=511'>512</a>\u001b[0m         attn_mask_g,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=512'>513</a>\u001b[0m         r,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=513'>514</a>\u001b[0m         seg_mat,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=514'>515</a>\u001b[0m         mems\u001b[39m=\u001b[39;49mmems,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=515'>516</a>\u001b[0m         target_mapping\u001b[39m=\u001b[39;49mtarget_mapping,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=516'>517</a>\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=517'>518</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=518'>519</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=519'>520</a>\u001b[0m     output_h, output_g \u001b[39m=\u001b[39m outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=521'>522</a>\u001b[0m     \u001b[39mif\u001b[39;00m output_g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py:439\u001b[0m, in \u001b[0;36mXLNetRelativeAttention.forward\u001b[0;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=435'>436</a>\u001b[0m k_head_r \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mibh,hnd->ibnd\u001b[39m\u001b[39m\"\u001b[39m, r\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr\u001b[39m.\u001b[39mdtype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr)\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=437'>438</a>\u001b[0m \u001b[39m# core attention ops\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=438'>439</a>\u001b[0m attn_vec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_attn_core(\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=439'>440</a>\u001b[0m     q_head_h,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=440'>441</a>\u001b[0m     k_head_h,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=441'>442</a>\u001b[0m     v_head_h,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=442'>443</a>\u001b[0m     k_head_r,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=443'>444</a>\u001b[0m     seg_mat\u001b[39m=\u001b[39;49mseg_mat,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=444'>445</a>\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattn_mask_h,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=445'>446</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=446'>447</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=447'>448</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=449'>450</a>\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=450'>451</a>\u001b[0m     attn_vec, attn_prob \u001b[39m=\u001b[39m attn_vec\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py:277\u001b[0m, in \u001b[0;36mXLNetRelativeAttention.rel_attn_core\u001b[0;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=273'>274</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Core relative positional attention operations.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=275'>276</a>\u001b[0m \u001b[39m# content based attention score\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=276'>277</a>\u001b[0m ac \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49meinsum(\u001b[39m\"\u001b[39;49m\u001b[39mibnd,jbnd->bnij\u001b[39;49m\u001b[39m\"\u001b[39;49m, q_head \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mr_w_bias, k_head_h)\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=278'>279</a>\u001b[0m \u001b[39m# position based attention score\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/transformers/models/xlnet/modeling_xlnet.py?line=279'>280</a>\u001b[0m bd \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mibnd,jbnd->bnij\u001b[39m\u001b[39m\"\u001b[39m, q_head \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_r_bias, k_head_r)\n",
      "File \u001b[0;32m~/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/functional.py?line=371'>372</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m einsum(equation, \u001b[39m*\u001b[39m_operands)\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/functional.py?line=373'>374</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(operands) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m opt_einsum\u001b[39m.\u001b[39menabled:\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/functional.py?line=374'>375</a>\u001b[0m     \u001b[39m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/functional.py?line=375'>376</a>\u001b[0m     \u001b[39m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/functional.py?line=376'>377</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49meinsum(equation, operands)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/functional.py?line=378'>379</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/varasheim/Desktop/tdt13ny/TDT13/myenv/lib/python3.11/site-packages/torch/functional.py?line=379'>380</a>\u001b[0m \u001b[39mif\u001b[39;00m opt_einsum\u001b[39m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 4.84 GB, other allocations: 1.88 GB, max allowed: 6.77 GB). Tried to allocate 96.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "from transformers import XLNetForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained XLNet model with a classification head\n",
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=6)  # We have 6 classes\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    output_dir='./results',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=200,\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
